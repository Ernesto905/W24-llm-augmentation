{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.chat_models import ChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.schema import (\n",
    "    AIMessage,\n",
    "    HumanMessage,\n",
    "    SystemMessage\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(model_name=\"gpt-3.5-turbo\", api_key=os.getenv(\"OPENAI_API_KEY\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```python\n",
      "import numpy as np\n",
      "import tensorflow as tf\n",
      "\n",
      "# Generate simulated data\n",
      "np.random.seed(0)\n",
      "X = np.random.rand(1000, 10)\n",
      "y = np.random.randint(0, 2, 1000)\n",
      "\n",
      "# Define the neural network model\n",
      "model = tf.keras.models.Sequential([\n",
      "    tf.keras.layers.Dense(64, activation='relu', input_shape=(10,)),\n",
      "    tf.keras.layers.Dense(64, activation='relu'),\n",
      "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
      "])\n",
      "\n",
      "# Compile the model\n",
      "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
      "\n",
      "# Train the model\n",
      "model.fit(X, y, epochs=10, batch_size=32)\n",
      "\n",
      "# Save the model\n",
      "model.save('simulated_model.h5')\n",
      "```\n",
      "\n"
     ]
    }
   ],
   "source": [
    "messages = [\n",
    "    SystemMessage(content=\"You are an expert data scientist.\"),\n",
    "    HumanMessage(content=\"Write a Python script that trains a neural network on simulated data. Only return the script.\")\n",
    "]\n",
    "\n",
    "response = llm(messages=messages, temperature=0)\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import LLMChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"\"\"\n",
    "Explain {topic} in one sentence\n",
    "\"\"\"\n",
    "\n",
    "prompt = PromptTemplate.from_template(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Large language models are advanced artificial intelligence systems that can process and generate human-like text based on vast amounts of training data.'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain = LLMChain(prompt=prompt, llm=llm)\n",
    "\n",
    "chain.run(topic=\"large language models\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "second_prompt = PromptTemplate(\n",
    "    input_variables=[\"ml_topic\"],\n",
    "    template=\"Turn the concept description of {ml_topic} into a blog post.\"\n",
    ")\n",
    "\n",
    "chain_two = LLMChain(llm=llm, prompt=second_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new SimpleSequentialChain chain...\u001b[0m\n",
      "\u001b[36;1m\u001b[1;3mAn autoencoder is a type of artificial neural network that aims to learn efficient representations of input data by compressing and then reconstructing it.\u001b[0m\n",
      "\u001b[33;1m\u001b[1;3mAutoencoders: Unveiling the Magic of Artificial Neural Networks\n",
      "\n",
      "Have you ever wondered how computers are able to understand and process complex data like images, text, and sounds? One key technology behind this capability is the autoencoder, a type of artificial neural network that is revolutionizing the field of machine learning.\n",
      "\n",
      "At its core, an autoencoder is designed to learn efficient representations of input data by compressing and then reconstructing it. This process involves feeding raw data into the network, which then encodes the information into a lower-dimensional space, known as the latent space. By doing so, the autoencoder is able to capture the essential features of the input data while discarding unnecessary details.\n",
      "\n",
      "Once the data is encoded, the network then decodes it back into its original form, using the learned representations to reconstruct the input. This reconstruction is not perfect, but rather a close approximation that captures the most important aspects of the data. By training the autoencoder on a large dataset, it can learn to extract meaningful patterns and relationships within the data, allowing it to generalize to unseen examples.\n",
      "\n",
      "Autoencoders have a wide range of applications across various domains, including image and speech recognition, anomaly detection, and data compression. For example, in image recognition, autoencoders can be used to reduce the dimensionality of high-resolution images, making them easier to process and analyze. In anomaly detection, autoencoders can identify unusual patterns or outliers in data, making them valuable tools for cybersecurity and fraud detection.\n",
      "\n",
      "Overall, autoencoders are a powerful tool for learning complex representations of data in an efficient and effective manner. As the field of artificial intelligence continues to advance, autoencoders will play an increasingly important role in unlocking the potential of machine learning and enabling computers to become more intelligent and capable. So next time you marvel at the incredible capabilities of your computer, remember that it's all thanks to the magic of autoencoders.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Autoencoders: Unveiling the Magic of Artificial Neural Networks\n",
      "\n",
      "Have you ever wondered how computers are able to understand and process complex data like images, text, and sounds? One key technology behind this capability is the autoencoder, a type of artificial neural network that is revolutionizing the field of machine learning.\n",
      "\n",
      "At its core, an autoencoder is designed to learn efficient representations of input data by compressing and then reconstructing it. This process involves feeding raw data into the network, which then encodes the information into a lower-dimensional space, known as the latent space. By doing so, the autoencoder is able to capture the essential features of the input data while discarding unnecessary details.\n",
      "\n",
      "Once the data is encoded, the network then decodes it back into its original form, using the learned representations to reconstruct the input. This reconstruction is not perfect, but rather a close approximation that captures the most important aspects of the data. By training the autoencoder on a large dataset, it can learn to extract meaningful patterns and relationships within the data, allowing it to generalize to unseen examples.\n",
      "\n",
      "Autoencoders have a wide range of applications across various domains, including image and speech recognition, anomaly detection, and data compression. For example, in image recognition, autoencoders can be used to reduce the dimensionality of high-resolution images, making them easier to process and analyze. In anomaly detection, autoencoders can identify unusual patterns or outliers in data, making them valuable tools for cybersecurity and fraud detection.\n",
      "\n",
      "Overall, autoencoders are a powerful tool for learning complex representations of data in an efficient and effective manner. As the field of artificial intelligence continues to advance, autoencoders will play an increasingly important role in unlocking the potential of machine learning and enabling computers to become more intelligent and capable. So next time you marvel at the incredible capabilities of your computer, remember that it's all thanks to the magic of autoencoders.\n"
     ]
    }
   ],
   "source": [
    "from langchain.chains import SimpleSequentialChain\n",
    "overall_chain = SimpleSequentialChain(chains=[chain, chain_two], verbose=True)\n",
    "\n",
    "blog_post = overall_chain.run(\"autoencoder\")\n",
    "print(blog_post)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
