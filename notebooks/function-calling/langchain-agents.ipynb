{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function Calling with LangChain Agents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we will leverage [Agents](https://python.langchain.com/docs/modules/agents/) in LangChain (particularly, custom-defined agents) to demonstrate the capabilities of function-calling-augmented LLMs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_community.chat_models import ChatOpenAI\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(\n",
    "    openai_api_key=os.getenv(\"OPENAI_API_KEY\"),\n",
    "    temperature=0,\n",
    "    model_name=\"gpt-3.5-turbo\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Calculator Function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Computers can solve complex math problems, yet if we ask GPT-3.5 (or GPT-4, for that matter) for the answer to `(4.5*2.1)^2.2`, it fails."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating the expression (4.5*2.1)^2.2:\n",
      "\n",
      "(4.5*2.1)^2.2 = (9.45)^2.2\n",
      "(9.45)^2.2 ≈ 94.5^2.2\n",
      "94.5^2.2 ≈ 1,048.52\n",
      "\n",
      "Therefore, (4.5*2.1)^2.2 is approximately 1,048.52.\n"
     ]
    }
   ],
   "source": [
    "print(llm.invoke(\"(4.5*2.1)^2.2\").content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To address this problem, we can leverage function calling to allow the LLM to use an actual calculator tool."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Creating a Custom Tool"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will create a tool that will evaluate basic arithmetic math problems. There many ways to define tools - we enumerate some of these approaches below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1.1 OOP Approach"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can define our own tools with an inheritance-based approach. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.tools import BaseTool\n",
    "\n",
    "class CalculatorTool(BaseTool):\n",
    "    # The name and description are required by LangChain - they are used to help the LLM figure out what tool to use\n",
    "    name = \"Calculator\"\n",
    "    description = \"A simple calculator tool that evaluates a mathemtical expression and returns the result as an integer. Do not pass untrusted input.\"\n",
    "    \n",
    "    def _run(self, input_expr: str) -> int:\n",
    "        # Evaluate the mathematical expression to get the result\n",
    "        # Replace ^ (mathematical exponent operator) with ** (python exponent operator)\n",
    "        return eval(input_expr.replace(\"^\", \"**\"), {}, {})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the `eval` function is generally very dangerous (but for the sake of this example, it's fine). `eval(str)` evaluates the input string as a literal Python expression, running whatever is contained inside the string. For instance, `eval(\"4.5 * 2\")` returns `9`, and `eval(\"[1, 2, 3]\")` returns a Python list with the values 1, 2, and 3. However, what this means is that `eval(\"os.system(\"rm -rf /\")\")` can also be ran...\n",
    "\n",
    "The two empty dictionaries we also pass as argument help to prevent some attacks, such as the `os.system` one; refer to the `eval` function's [documentation](https://realpython.com/python-eval-function/) to learn why. In practice, you would be best served using the `literal_eval` function from the `ast` library."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1.2 Function Decorator Approach"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another method for custom tool definition is through the use of function [decorators](https://www.geeksforgeeks.org/decorators-in-python/) (a more advanced Python concept)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.tools import tool\n",
    "\n",
    "@tool\n",
    "def calculator(input_expr: str) -> int:\n",
    "    \"\"\"A simple calculator tool that evaluates a mathemtical expression and returns the result as an integer. Do not pass untrusted input.\"\"\"\n",
    "    return eval(input_expr.replace(\"^\", \"**\"), {}, {})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Defining an Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# when giving tools to LLM, we must pass them as a list of tools\n",
    "# tools = [CalculatorTool]\n",
    "tools = [calculator]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ernesto/umich/DSClub/W24-llm-augmentation/venv/lib/python3.9/site-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The function `initialize_agent` was deprecated in LangChain 0.1.0 and will be removed in 0.2.0. Use Use new agent constructor methods like create_react_agent, create_json_agent, create_structured_chat_agent, etc. instead.\n",
      "  warn_deprecated(\n",
      "/Users/ernesto/umich/DSClub/W24-llm-augmentation/venv/lib/python3.9/site-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The function `__call__` was deprecated in LangChain 0.1.0 and will be removed in 0.2.0. Use invoke instead.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mI need to calculate the result of the expression (4.5*2.1)^2.2\n",
      "Action: calculator\n",
      "Action Input: (4.5*2.1)^2.2\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m139.94261298333066\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mI now know the final answer\n",
      "Final Answer: 139.94261298333066\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'what is (4.5*2.1)^2.2?', 'output': '139.94261298333066'}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.agents import initialize_agent\n",
    "\n",
    "zero_shot_agent = initialize_agent(\n",
    "    agent=\"zero-shot-react-description\",\n",
    "    tools=tools,\n",
    "    llm=llm,\n",
    "    verbose=True,\n",
    "    max_iterations=3\n",
    ")\n",
    "\n",
    "zero_shot_agent(\"what is (4.5*2.1)^2.2?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: If you are running into weird errors with the tools, try restarting your kernel."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Using an Existing Tool"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LangChain's [LLMMathChain](https://api.python.langchain.com/en/latest/chains/langchain.chains.llm_math.base.LLMMathChain.html) would be a good solution here. The LLMMathChain turns math problems into Python Code (using the LLM) and runs the code to obtain the result. This would be very helpful for more complicated math problems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ernesto/umich/DSClub/W24-llm-augmentation/venv/lib/python3.9/site-packages/langchain/chains/llm_math/base.py:57: UserWarning: Directly instantiating an LLMMathChain with an llm is deprecated. Please instantiate with llm_chain argument or using the from_llm class method.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from langchain.chains import LLMMathChain\n",
    "from langchain.agents import Tool\n",
    "\n",
    "llm_math = LLMMathChain(llm=llm)\n",
    "\n",
    "# initialize the math tool\n",
    "math_tool = Tool(\n",
    "    name='Calculator',\n",
    "    func=llm_math.run,\n",
    "    description='Useful for when you need to answer questions about math.'\n",
    ")\n",
    "# when giving tools to LLM, we must pass them as a list of tools\n",
    "tools = [math_tool]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mI need to calculate the result of raising (4.5*2.1) to the power of 2.2.\n",
      "Action: Calculator\n",
      "Action Input: (4.5*2.1)^2.2\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mAnswer: 139.94261298333066\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mI now know the final answer\n",
      "Final Answer: 139.94\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'what is (4.5*2.1)^2.2?', 'output': '139.94'}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.agents import initialize_agent\n",
    "\n",
    "zero_shot_agent = initialize_agent(\n",
    "    agent=\"zero-shot-react-description\",\n",
    "    tools=tools,\n",
    "    llm=llm,\n",
    "    verbose=True,\n",
    "    max_iterations=3\n",
    ")\n",
    "\n",
    "zero_shot_agent(\"what is (4.5*2.1)^2.2?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Your Turn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, create a function calling application of your own. You are encouraged to use external APIs to create robust tools. Refer to `simple-weather-llm.py` for an example tool."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Idea: Philosophy Multiplexer \n",
    "A main bot will recieve input from a user, and then decide whether this question falls under the following categories:\n",
    "- Epistemology -- https://plato.stanford.edu/entries/epistemology/\n",
    "- Moral theory -- https://plato.stanford.edu/entries/moral-theory/\n",
    "- Metaphysics -- https://plato.stanford.edu/entries/metaphysics/\n",
    "- Linguistics -- https://plato.stanford.edu/entries/linguistics/\n",
    "- Axiology -- https://plato.stanford.edu/entries/value-theory/\n",
    "- Aesthetics -- https://plato.stanford.edu/entries/aesthetic-concept/\n",
    "- Theology -- https://plato.stanford.edu/entries/philosophy-religion/\n",
    "- Political philosophy (Focus on the concept of authority) -- https://plato.stanford.edu/entries/authority/\n",
    "- \n",
    "It will provison an expert from each of the fields. Each expert will have access to a vector database where within i'll store the stanford encyclopedia of philosophy entry corresponding to that topic, as linked above.\n",
    "\n",
    "##### Optional: figure out a way to carry on conversations\n",
    "##### Optional^2: figure out a way to make these bots conversate with each other. E.g. \n",
    "```PMux -> Epistemology -> PMux -> Theology -> Pmux -> Axiology -> ...```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The file philosophy_docs/epistemology.html already exists, skipping download.\n",
      "The file philosophy_docs/moral-theory.html already exists, skipping download.\n",
      "The file philosophy_docs/metaphysics.html already exists, skipping download.\n",
      "The file philosophy_docs/linguistics.html already exists, skipping download.\n",
      "The file philosophy_docs/axiology.html already exists, skipping download.\n",
      "The file philosophy_docs/aesthetics.html already exists, skipping download.\n",
      "The file philosophy_docs/theology.html already exists, skipping download.\n",
      "The file philosophy_docs/political-philosophy.html already exists, skipping download.\n"
     ]
    }
   ],
   "source": [
    "# Run to get updated encyclopedia entries\n",
    "!./create_philosophy_directory.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyTool(BaseTool):\n",
    "    name = \"The name of the tool\"\n",
    "    description = \"A description of the tool\"\n",
    "\n",
    "    # change the arguments as needed\n",
    "    def _run(self, **kwargs):\n",
    "        return \"Hello, World!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import UnstructuredHTMLLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "import tiktoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "aesthetics_loader = UnstructuredHTMLLoader(\"philosophy_docs/aesthetics.html\")\n",
    "axiology_loader = UnstructuredHTMLLoader(\"philosophy_docs/axiology_loader.html\")\n",
    "epistemology_loader = UnstructuredHTMLLoader(\"philosophy_docs/epistemology.html\")\n",
    "linguistics_loader = UnstructuredHTMLLoader(\"philosophy_docs/linguistics.html\")\n",
    "metaphysics_loader = UnstructuredHTMLLoader(\"philosophy_docs/metaphysics.html\")\n",
    "moraltheory_loader = UnstructuredHTMLLoader(\"philosophy_docs/moral-theory.html\")\n",
    "politicalphilosophy_loader = UnstructuredHTMLLoader(\"philosophy_docs/political-philosophy.html\")\n",
    "theology_loader = UnstructuredHTMLLoader(\"philosophy_docs/theology.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = tiktoken.get_encoding(\"cl100k_base\")\n",
    "\n",
    "# create the length function\n",
    "def tiktoken_len(text):\n",
    "    tokens = tokenizer.encode(\n",
    "        text,\n",
    "        disallowed_special=()\n",
    "    )\n",
    "    return len(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=400,\n",
    "    chunk_overlap=20,\n",
    "    length_function=tiktoken_len,\n",
    "    separators=['\\n\\n', '\\n', ' ', '']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunks = text_splitter.split_text()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
